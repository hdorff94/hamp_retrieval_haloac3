{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyPamtra\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates the input for readERA5\n",
    "from cdo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERA5 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ERA5_Preprocessing():\n",
    "    \n",
    "    def __init__(self,yyyy,mm,dd,descriptor_file,outPath=\"/tmp/\",area=[-30,50,65,89]):\n",
    "        self.threads=\"32\"\n",
    "        self.outPath=outPath\n",
    "        self.yyyy=yyyy\n",
    "        self.mm=mm\n",
    "        self.dd=dd\n",
    "        self.descriptor_file=descriptor_file\n",
    "        self.area=area\n",
    "    \n",
    "    def runCDO(self,timestep=1):\n",
    "        cdo = Cdo()\n",
    "        yyyy = str(self.yyyy)\n",
    "        mm = \"%02d\" % (self.mm,)\n",
    "        dd = \"%02d\" % (self.dd,)\n",
    "        outtime = \"%02d\" % (timestep-1,)\n",
    "        area = ','.join([str(coord) for coord in area])\n",
    "        self.era5_datetime = yyyy+mm+dd+\"_\"+outtime\n",
    "        # Run the CDO commands\n",
    "        cdo_string = \"-sp2gpl -seltimestep,\" + str(timestep) +\\\n",
    "                        \" -setgridtype,regular \"+\"/pool/data/ERA5/ml00_1H/\"+\\\n",
    "                            yyyy+\"/E5ml00_1H_\"+yyyy+\"-\"+mm+\"-\"+dd+\"_130\"\n",
    "        cdo.sellonlatbox(area,input=cdo_string, output=outPath+\"reduced_ml_\"+era5_datetime+\"_130.nc\",\n",
    "                         options='-f nc -P ' + threads)\n",
    "        # ERA Variables are labelled with numbers\n",
    "        for var in ['075', '076', '133', '246', '247']:\n",
    "            cdo_string = \"-seltimestep,\" + str(timestep) +\" -setgridtype,regular \"+\"/pool/data/ERA5/ml00_1H/\"+\\\n",
    "                            yyyy+\"/E5ml00_1H_\"+yyyy+\"-\"+mm+\"-\"+dd+\"_\"+var\n",
    "            cdo.sellonlatbox(area,input=cdo_string, output=outPath+\"reduced_ml_\"+self.era5_datetime+\"_\"+var+\".nc\",\n",
    "                             options='-f nc -P ' + threads)\n",
    "    \n",
    "        for var in ['031','034','129','134','137','151','165','166','172','235']:\n",
    "            cdo_string = \"-seltimestep,\" + str(timestep) +\" -selday,\"+dd+\" -setgridtype,regular \"+\"/pool/data/ERA5/sf00_1H/\"+\\\n",
    "                            yyyy+\"/E5sf00_1H_\"+yyyy+\"-\"+mm+\"_\"+var\n",
    "            cdo.sellonlatbox(area,input=cdo_string, output=outPath+\"reduced_sf_\"+self.era5_datetime+\"_\"+var+\".nc\", \n",
    "                             options='-f nc -P ' + threads)\n",
    "\n",
    "        #return era5_datetime\n",
    "\n",
    "    def readERA5(self,inPath='/tmp/',debug=False,verbosity=0,step=1,cut_levels=None):\n",
    "        \"\"\"\n",
    "        import ERA5 full model output from netcdf files\n",
    "    \n",
    "        netcdf files have been created with cdo by extracting desired timestep and lat/lon region \n",
    "        for all variables needed and converting the temperature from spherical harmonics to Gaussian linear grid. \n",
    "\n",
    "        2d vars: 031 034 129 134 137 151 165 166 172 235\n",
    "        cdo -f nc -P $threads -seltimestep,$timestep -selday,$dd -sellonlatbox,\n",
    "            $minlon,$maxlon,$minlat,$maxlat -setgridtype,regular gribfile ncfile\n",
    "        3d vars: 075 076 133 246 247 130\n",
    "        cdo -f nc -P $threads -sellonlatbox,$minlon,$maxlon,$minlat,$maxlat\n",
    "            [-setgridtype,regular|-sp2gpl] -seltimestep,$timestep gribfile ncfile\n",
    "\n",
    "        era5_datetime: yyyymmmdd_hh of the model output\n",
    "        descriptorfile: ECMWF descriptorfile\n",
    "        debug: switch on debugging\n",
    "        verbosity: increase verbosity\n",
    "        step: reduce ERA5 grid to nth point in lat/lon\n",
    "        cut_levels: cut atmosphere from top. This is necessary, \n",
    "                        cause PAMTRA can not calculate gas absorption for pressure below 3hPa. \n",
    "                        A sufficiently good value for cut_levels is 5.\n",
    "        \"\"\"\n",
    "\n",
    "        if debug: import pdb;pdb.set_trace()\n",
    "        # parameters\n",
    "        self.R_d = 287.0597\n",
    "        self.R_v = 461.5250\n",
    "        self.g = 9.80665\n",
    "        self.R = 6371229\n",
    "\n",
    "        # read constant file for pressure level calculation\n",
    "        dataC = np.genfromtxt('/home/b/b380702/pamtra/data/era5_ecmwf_akbk.csv',\n",
    "                              usecols=[1,2],skip_header=1,delimiter=',')\n",
    "        ak, bk = dataC[-1:cut_levels:-1,0],dataC[-1:cut_levels:-1,1]\n",
    "\n",
    "        # define and get 2d vars\n",
    "        self.vals2D = dict()\n",
    "        vals2D_params = {'031':'ci','034':'sst',\n",
    "                         '129':'z','134':'sp',\n",
    "                         '151':'msl','165':'10u',\n",
    "                         '166':'10v','172':'lsm',\n",
    "                         '235':'skt'}\n",
    "\n",
    "        for key,value in vals2D_params.items():\n",
    "            self.tmp_ds = xr.open_dataset(inPath+'reduced_sf_'+self.era5_datetime+'_'+key+'.nc')\n",
    "            self.vals2D[value] = np.squeeze(np.swapaxes(self.tmp_ds['var'+str(int(key))].values,1,2))[0::step,0::step]\n",
    "\n",
    "        # define and get 3d vars\n",
    "        self.vals3D = dict()\n",
    "        vals3D_params = {'075':'crwc','076':'cswc',\n",
    "                         '130':'t','133':'q',\n",
    "                         '246':'clwc','247':'ciwc'}\n",
    "\n",
    "        for key,value in vals3D_params.items():\n",
    "            self.tmp_ds = xr.open_dataset(inPath+'reduced_ml_'+self.era5_datetime+'_'+key+'.nc')\n",
    "            self.vals3D[value] = np.squeeze(np.swapaxes(self.tmp_ds[value].values,1,3)[...,-1:cut_levels:-1])[0::step,0::step,:]\n",
    "\n",
    "        # set grid size for the data\n",
    "        (self.Nx,self.Ny,self.Nz) = vals3D['t'].shape\n",
    "        self.nHydro = 4 # ERA5 has 4 hydrometeor classes\n",
    "\n",
    "        self.shape2D = (self.Nx,self.Ny)\n",
    "        self.shape3D = (self.Nx,self.Ny,self.Nz)\n",
    "        self.shape3Dplus = (self.Nx,self.Ny,self.Nz+1)\n",
    "        self.shape4D = (self.Nx,self.Ny,self.Nz,self.nHydro)\n",
    "\n",
    "        # time in seconds since 1970 UTC\n",
    "        self.unixtime = np.zeros(self.shape2D)\n",
    "        self.unixtime[:] = tmp_ds['time'][0].astype(int)/ 10**9\n",
    "    \n",
    "    def create_pamData_dict(self,step=1):\n",
    "        pamData = dict()\n",
    "\n",
    "        pamData['timestamp'] = self.unixtime\n",
    "\n",
    "        # create latitude and longitude grid\n",
    "        pamData['lat'] = np.tile(self.tmp_ds['lat'][0::step].values,(self.Nx,1))\n",
    "        pamData['lon'] = np.tile(self.tmp_ds['lon'][0::step].values,(self.Ny,1)).T\n",
    "\n",
    "        # create temperature field\n",
    "        pamData['temp'] = self.vals3D['t']\n",
    "        pamData['temp_lev'] = np.empty(self.shape3Dplus)\n",
    "        pamData['temp_lev'][...,1:-1] = (pamData['temp'][...,1:] + pamData['temp'][...,0:-1])*0.5\n",
    "        pamData['temp_lev'][...,-1] = pamData['temp_lev'][...,-2]+ (pamData['temp_lev'][...,-2] - pamData['temp_lev'][...,-3])*0.5\n",
    "        pamData['temp_lev'][...,0] = vals2D['skt'][...]\n",
    "\n",
    "        # surface geopotential\n",
    "        z_sfc = self.vals2D['z'][:,:]\n",
    "\n",
    "        # height and pressure grid\n",
    "        pamData['hgt'] = np.empty(self.shape3D)\n",
    "        pamData['hgt_lev'] = np.empty(self.shape3Dplus)\n",
    "        pamData['press'] = np.empty(self.shape3D)\n",
    "        pamData['press_lev'] = np.empty(self.shape3Dplus)\n",
    "        pamData['hgt_lev'][...,0] = z_sfc/g\n",
    "        # pamData['hgt_lev'][...,0] = z_sfc/g*R/(R-z_sfc/g)\n",
    "\n",
    "        sfc_press = self.vals2D['sp']\n",
    "        msl_press = self.vals2D['msl']\n",
    "\n",
    "        q = self.vals3D['q']\n",
    "\n",
    "        for i in range(self.Nz+1):\n",
    "            pamData['press_lev'][...,i] = sfc_press*bk[i]+ak[i]\n",
    "        pamData['press'][...,:] = (pamData['press_lev'][...,1:] + pamData['press_lev'][...,0:-1])*0.5\n",
    "        \n",
    "        # hydrometeors\n",
    "        pamData['hydro_q'] = np.zeros(self.shape4D) + np.nan\n",
    "        pamData['hydro_q'][...,0] = self.vals3D['clwc']\n",
    "        pamData['hydro_q'][...,1] = self.vals3D['ciwc']\n",
    "        pamData['hydro_q'][...,2] = self.vals3D['crwc']\n",
    "        pamData['hydro_q'][...,3] = self.vals3D['cswc']\n",
    "\n",
    "        qh = np.zeros(self.shape3D)\n",
    "        qh = np.sum(pamData['hydro_q'],axis=3)\n",
    "\n",
    "        z = np.zeros(self.shape2D)\n",
    "        t_v = np.zeros(self.shape3D)\n",
    "        t_v = pamData['temp'][...] * (1+((self.R_v/self.R_d)-1)*self.q)\n",
    "        pdlog = np.zeros(self.shape3D)\n",
    "        pdlog = np.log(pamData['press_lev'][...,0:-1]/pamData['press_lev'][...,1:])\n",
    "        for k in range(self.shape3Dplus[2]):\n",
    "            z[:,:] = 0\n",
    "            for k2 in range(0,k):\n",
    "                z[:,:] += self.R_d*t_v[:,:,k2]*pdlog[:,:,k2]\n",
    "            z[:,:] = z[:,:] + z_sfc\n",
    "            pamData['hgt_lev'][:,:,k] = z[:,:]/g\n",
    "        # pamData['hgt_lev'][...,k] =z/g*R/(R-z/g)\n",
    "        pamData['hgt'] = (pamData['hgt_lev'][...,1:] + pamData['hgt_lev'][...,:-1])*0.5\n",
    "        # create relative humidity field\n",
    "        pamData['relhum'] = np.empty(shape3D)\n",
    "\n",
    "        pamData['relhum'][:,:,:] = (pyPamtra.meteoSI.q2rh(q,pamData['temp'][:,:,:],\n",
    "                                                          pamData['press'][:,:,:]) * 100.)\n",
    "\n",
    "        # fill remaining vars that need no conversion\n",
    "        varPairs = [['10u','wind10u'],['10v','wind10v'],['skt','groundtemp'],['lsm','sfc_slf'],['ci','sfc_sif']]\n",
    "        for era5Var,pamVar in varPairs:\n",
    "            pamData[pamVar] = np.zeros(shape2D)\n",
    "            pamData[pamVar][:,:] = self.vals2D[era5Var][:,:]\n",
    "            print(era5Var,pamData[pamVar].shape)\n",
    "\n",
    "        # surface properties\n",
    "        pamData['sfc_type'] = np.around(pamData['sfc_slf']).astype('int32')\n",
    "        pamData['sfc_model'] = np.zeros(shape2D, dtype='int32')\n",
    "        pamData['sfc_refl'] = np.chararray(shape2D,unicode=True)\n",
    "        pamData['sfc_refl'][:] = 'F'\n",
    "        pamData['sfc_refl'][pamData['sfc_type'] > 0] = 'S'\n",
    "\n",
    "        # sea ice is taken from telsem2 and defined to be Lambertian\n",
    "        ice_idx = (pamData['sfc_sif'] > 0)\n",
    "        pamData['sfc_type'][ice_idx] = 1\n",
    "        pamData['sfc_model'][ice_idx] = 0\n",
    "        pamData['sfc_refl'][ice_idx] = 'L'\n",
    "        self.pamData=pamData\n",
    "    \n",
    "    def create_pyPamtra_obj(self):\n",
    "        self.pam = pyPamtra.pyPamtra()\n",
    "        self.pam.set['pyVerbose']= verbosity\n",
    "\n",
    "        # read descriptorfile\n",
    "        if isinstance(self.descriptorFile, str):\n",
    "            self.pam.df.readFile(self.descriptorFile)\n",
    "        else:\n",
    "            for df in self.descriptorFile:\n",
    "                self.pam.df.addHydrometeor(df)\n",
    "\n",
    "        # create pam profiles\n",
    "        self.pam.createProfile(**self.pamData)\n",
    "        self.pam.addIntegratedValues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PAMTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPAMTRA(ERA5_processing_cls, mode='passive'):\n",
    "    pam=ERA5_processing_cls.pam\n",
    "    if mode == 'active':\n",
    "        pass # so far unused\n",
    "        \"\"\"\n",
    "        # General settings for the Doppler spectra simulations\n",
    "\n",
    "        pam.nmlSet['active'] = True\n",
    "        pam.nmlSet['radar_mode'] = 'spectrum' # 'spectrum'\n",
    "        pam.nmlSet['passive'] = False # Passive is time consuming\n",
    "        pam.set['verbose'] = 0 # set verbosity levels\n",
    "        pam.set['pyVerbose'] = 0 # change to 2 if you want to see job progress number on the output\n",
    "        # pam.p['turb_edr'][:] = 1.0e-4\n",
    "        pam.nmlSet['radar_airmotion'] = True\n",
    "        #pam.nmlSet['radar_airmotion_vmin'] = 0.0 # workaround to potential bug in radar_spectrum\n",
    "        pam.nmlSet['radar_airmotion_model'] = 'constant'\n",
    "\n",
    "        # Instrument specific settings (W-band radar Joyrad94)\n",
    "        pam.nmlSet['radar_fwhr_beamwidth_deg']=0.5\n",
    "        pam.nmlSet['radar_integration_time']=1.0\n",
    "        pam.nmlSet['radar_max_v']=6.8\n",
    "        pam.nmlSet['radar_min_v']=-6.8\n",
    "        pam.nmlSet['radar_nfft']=512\n",
    "        pam.nmlSet['radar_no_ave']=17\n",
    "        pam.nmlSet['radar_pnoise0']=-100#-54.0\n",
    "        pam.runParallelPamtra(np.array([35.5, 94.0, 155.5, 167., 174.8]), pp_deltaX=1000, pp_deltaY=1, pp_deltaF=1)\n",
    "        pam.writeResultsToNetCDF('/scratch/b/b380702/'+campaign+'_'+flight+'_'+date+'_'+pam.nmlSet[\"radar_mode\"][:3]+'.nc',xarrayCompatibleOutput=True)\n",
    "        \"\"\"\n",
    "    elif mode == 'passive':\n",
    "        pam.nmlSet['active'] = False\n",
    "        pam.nmlSet['passive'] = True # Passive is time consuming\n",
    "        pam.set['verbose'] = 0 # set verbosity levels\n",
    "        pam.set['pyVerbose'] = 0 # change to 2 if you want to see job progress number on the output\n",
    "        pam.p['noutlevels'] = 71\n",
    "        pam.p['obs_height'] = np.zeros((pam._shape2D[0],pam._shape2D[1],pam.p['noutlevels']))\n",
    "        pam.p['obs_height'][:,:,:] = [833000., 12000., 11900., 11800., 11700., 11600., 11500., 11400., 11300., 11200.,\n",
    "           11100., 11000., 10900., 10800., 10700., 10600., 10500., 10400.,\n",
    "           10300., 10200., 10100., 10000.,  9900.,  9800.,  9700.,  9600.,\n",
    "           9500.,  9400.,  9300.,  9200.,  9100.,  9000., 8900., 8800., 8700., 8600., 8500.,\n",
    "           5200., 5100., 5000., 4900., 4800., 4700., 4600., 4500., 4400., 4300., 4200., 4100., 4000.,\n",
    "           3900., 3800., 3700., 3600.,3500., 3400., 3300., 3200., 3100., 3000., 2900., 2800., 2700.,\n",
    "           2600., 2500., 2400., 2300., 2200., 2100., 2000., 0.\n",
    "            ]\n",
    "        \n",
    "        freqs = np.array([22.24,23.04,23.84,25.44,26.24,27.84,31.4,\n",
    "                          50.3,51.76,52.8,53.75,54.94,56.66,58.,89.,90.,\n",
    "                          110.25,114.55,116.45,117.35,120.15,121.05,122.95,127.25,\n",
    "                          155.5,167.,170.81,174.8,175.81,178.31,179.81,\n",
    "                          180.81,181.81,182.71,183.91,184.81,185.81,186.81,188.31,190.81,195.81,243.,340.])\n",
    "        #freqs = np.array([89.])\n",
    "        pam.runParallelPamtra(freqs, pp_deltaX=1, pp_deltaY=1,\n",
    "                              pp_deltaF=1,pp_local_workers=64)\n",
    "        pam.addIntegratedValues()\n",
    "        pam.writeResultsToNetCDF('/scratch/b/b380702/'+ERA5_processing_cls.era5_datetime+\\\n",
    "                                 '_passive.nc',xarrayCompatibleOutput=True,wpNames=['cwp','iwp','rwp','swp'])\n",
    "    else:\n",
    "        pam.addIntegratedValues()\n",
    "        print('Just reading')\n",
    "    return pam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducePamtraResults(pam,instrument='mirac-a',outPath='/scratch/b/b380702/'):\n",
    "    def read_attributes():\n",
    "        \"\"\"\n",
    "        Read variable definitions catalog\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cat\n",
    "\n",
    "        \"\"\"\n",
    "        import yaml\n",
    "        with open('/work/bb1320/scripts/instrument_settings.yaml', 'r') as f:\n",
    "\n",
    "            cat = yaml.safe_load(f)\n",
    "\n",
    "        return cat\n",
    "    cat = read_attributes()\n",
    "    out_slice = slice(cat[instrument]['obs_heights'][0],cat[instrument]['obs_heights'][1]+1)\n",
    "    ang_slice = slice(cat[instrument]['angles'][0],cat[instrument]['angles'][1]+1)\n",
    "    freq_slice = slice(cat[instrument]['frequencies'][0],cat[instrument]['frequencies'][1]+1)\n",
    "    tb = np.zeros((pam.p['ngridx'],pam.p['ngridy'],cat[instrument]['nout'],cat[instrument]['nang'],cat[instrument]['nfreq'],cat[instrument]['npol']))\n",
    "    tb[:,:,:,:,:,:] = pam.r['tb'][:,:,out_slice,ang_slice,freq_slice,:]\n",
    "    #import pdb;pdb.set_trace()\n",
    "    pam_ds = xr.Dataset(\n",
    "        {\"unixtime\": ((\"x\", \"y\"), pam.p['unixtime'][...]),\n",
    "         \"lat\": ((\"x\", \"y\"), pam.p['lat'][...]),\n",
    "         \"lon\": ((\"x\", \"y\"), pam.p['lon'][...]),\n",
    "         \"obs_height\": (['nout'], pam.p['obs_height'][0,0,slice(cat[instrument]['obs_heights'][0],cat[instrument]['obs_heights'][1]+1)]),\n",
    "         \"ang\": (['nang'], np.absolute(pam.r['angles_deg'][ang_slice]-180.)),\n",
    "         \"freq\": (['nfreq'], pam.set['freqs'][freq_slice]),\n",
    "         \"pol\": (['npol'],['H','V']),\n",
    "         \"tb\": ((\"x\", \"y\",\"nout\",\"nang\",\"nfreq\",\"npol\"), tb),\n",
    "        },)\n",
    "    pam_ds['tb'].attrs['units'] = 'K'\n",
    "\n",
    "    pam_ds.attrs['description'] = 'Reduced simulated brightness temperatures for %s based on ERA5 ouput.' % (instrument)\n",
    "    pam_ds.attrs['models'] =  'ERA5 + PAMTRA'\n",
    "    pam_ds.attrs['date'] =  datetime.datetime.utcfromtimestamp(pam.p['unixtime'][0,0]).strftime('%Y%m%d %H:%M')\n",
    "    \n",
    "    outFile = 'pamtra_' + instrument + '_' + datetime.datetime.utcfromtimestamp(pam.p['unixtime'][0,0]).strftime('%Y%m%d_%H') + '.nc'\n",
    "    \n",
    "    pam_ds.to_netcdf(outPath + outFile)\n",
    "\n",
    "    return pam_ds\n",
    "Neu\n",
    "10:43 Uhr\n",
    "def collectERA5(era5_datetime,inPath='/scratch/b/b380702/',outPath='/scratch/b/b380702/',step=4,cut_levels=5, applyFilter=False):\n",
    "    \"\"\"\n",
    "    Collects the ERA5 data from nc files generated by runCDO, adds integrated values, and dumps everything to nc-files.\n",
    "\n",
    "    applyFilter  if True, only selects ocean pixels\n",
    "    \"\"\"\n",
    "    def addIntegratedValues():\n",
    "        \"\"\"\n",
    "        Sums up hydrometeors and integrated  water vapor from bottom to all observation heights \n",
    "        in pam object. This results in dataset of size (x,y,nout).\n",
    "        Temperature, pressure and humidity are stored as full grid.\n",
    "        \"\"\"\n",
    "        def calcMoistRho():\n",
    "            \"\"\"\n",
    "            Calculates the wet density of gridbox.\n",
    "            \"\"\"\n",
    "            pam._helperP = dict()\n",
    "            pam._helperP['dz'] = pam.p['hgt_lev'][...,1::]-pam.p['hgt_lev'][...,0:-1]\n",
    "            pam._helperP['vapor'] = rh2q(pam.p['relhum']/100.,pam.p['temp'],pam.p['press'])\n",
    "            pam._helperP['sum_hydro_q'] = np.nansum(pam.p['hydro_q'],axis=-1)\n",
    "            pam._helperP['rho_moist'] =            moist_rho_rh(pam.p['press'],pam.p['temp'],pam.p['relhum']/100.,pam._helperP['sum_hydro_q'])\n",
    "\n",
    "            return\n",
    "\n",
    "        pam._shape4Dret = (pam.p[\"ngridx\"],pam.p[\"ngridy\"],pam.p['noutlevels'],pam.df.nhydro)\n",
    "        pam._shape3Dret = (pam.p[\"ngridx\"],pam.p[\"ngridy\"],pam.p['noutlevels'])\n",
    "        pam.p['hydro_wp'] = np.zeros(pam._shape4Dret)\n",
    "        pam._calcMoistRho() # provies as well dz, sum_hydro_q, and q within dict() self._helperP\n",
    "        pam.p['iwv'] = np.zeros(pam._shape3Dret)\n",
    "        for h in range(pam.p['noutlevels']):\n",
    "            target_height = pam.p['obs_height'][0,0,h]\n",
    "            for ix in range(pam.p[\"ngridx\"]):\n",
    "                zgrid = pam.p['hgt_lev'][ix,0,:]\n",
    "                z_diffs = np.absolute(zgrid - target_height)\n",
    "                z_index = np.argmin(z_diffs)+1\n",
    "                #print(z_index)\n",
    "                #print(target_height, pam.p['hgt_lev'][ix,0,z_index-1], pam.p['hgt_lev'][ix,0,z_index], pam.p['hgt_lev'][ix,0,z_index+1])\n",
    "                pam.p['iwv'][...,h] = np.nansum(pam._helperP['vapor'][...,0:z_index]*pam._helperP[\"rho_moist\"][...,0:z_index]*pam._helperP[\"dz\"][...,0:z_index],axis=-1)\n",
    "                #nothing to do without hydrometeors:\n",
    "                if np.all(pam.p['hydro_q']==0):\n",
    "                    self.p['hydro_wp'] = np.zeros(pam._shape4Dret)\n",
    "                else:\n",
    "                    for i in range(pam.df.nhydro):\n",
    "                        pam.p['hydro_wp'][...,h,i] = np.nansum(pam.p['hydro_q'][...,0:z_index,i]*pam._helperP[\"rho_moist\"][...,0:z_index]*pam._helperP[\"dz\"][...,0:z_index],axis=-1)\n",
    "\n",
    "        return\n",
    "\n",
    "    pam = readERA5(era5_datetime,'/home/b/b380702/pamtra/descriptorfiles/descriptor_file_ecmwf.txt',inPath=inPath,step=step,cut_levels=cut_levels)\n",
    "    pam.p['noutlevels'] = 71\n",
    "    pam.p['obs_height'] = np.zeros((pam._shape2D[0],pam._shape2D[1],pam.p['noutlevels']))\n",
    "    pam.p['obs_height'][:,:,:] = [833000., 12000., 11900., 11800., 11700., \n",
    "        11600., 11500., 11400., 11300., 11200.,\n",
    "       11100., 11000., 10900., 10800., 10700., 10600., 10500., 10400.,\n",
    "       10300., 10200., 10100., 10000.,  9900.,  9800.,  9700.,  9600.,\n",
    "        9500.,  9400.,  9300.,  9200.,  9100.,  9000., 8900., 8800., 8700., \n",
    "        8600., 8500., 5200., 5100., 5000., 4900., 4800., 4700., 4600., 4500., \n",
    "        4400., 4300., 4200., 4100., 4000., 3900., 3800., 3700., 3600.,\n",
    "        3500., 3400., 3300., 3200., 3100., 3000., 2900., 2800., 2700.,\n",
    "        2600., 2500., 2400., 2300., 2200., 2100., 2000., 0.]\n",
    "    if applyFilter:\n",
    "        filter = np.empty(pam._shape2D,dtype=bool)\n",
    "        filter[:,:] = False\n",
    "        filter[pam.p['sfc_type'] == 0] = True\n",
    "        pam.filterProfiles(filter)\n",
    "    \n",
    "    addIntegratedValues()\n",
    "    era5_ds = xr.Dataset(\n",
    "        {\"unixtime\": ((\"x\", \"y\"), pam.p['unixtime'][...]),\n",
    "         \"lat\": ((\"x\", \"y\"), pam.p['lat'][...]),\n",
    "         \"lon\": ((\"x\", \"y\"), pam.p['lon'][...]),\n",
    "         \"obs_height\": ((\"nout\"), pam.p['obs_height'][0,0,:]),\n",
    "         \"sfc_slf\": ((\"x\", \"y\"), pam.p['sfc_slf'][...]),\n",
    "         \"sfc_sif\": ((\"x\", \"y\"), pam.p['sfc_sif'][...]),\n",
    "         \"groundtemp\": ((\"x\", \"y\"), pam.p['groundtemp'][...]),\n",
    "         \"hgt\": ((\"x\", \"y\", \"z\"), pam.p['hgt'][...]),\n",
    "         \"t\": ((\"x\", \"y\", \"z\"), pam.p['temp'][...]),\n",
    "         \"rh\":((\"x\", \"y\", \"z\"), pam.p['relhum'][...]),\n",
    "         \"p\":((\"x\", \"y\", \"z\"), pam.p['press'][...]),\n",
    "         \"iwv\":((\"x\", \"y\", \"nout\"), pam.p['iwv'][...]),\n",
    "         \"cwp\":((\"x\", \"y\", \"nout\"), pam.p['hydro_wp'][...,0]),\n",
    "         \"iwp\":((\"x\", \"y\", \"nout\"), pam.p['hydro_wp'][...,1]),\n",
    "         \"rwp\":((\"x\", \"y\", \"nout\"), pam.p['hydro_wp'][...,2]),\n",
    "         \"swp\":((\"x\", \"y\", \"nout\"), pam.p['hydro_wp'][...,3]),},)\n",
    "\n",
    "    era5_ds['unixtime'].attrs['units'] = 'seconds since 1970-01-01 00:00:00'\n",
    "    era5_ds['obs_height'].attrs['units'] = 'm'\n",
    "    era5_ds['groundtemp'].attrs['units'] = 'K'\n",
    "    era5_ds['hgt'].attrs['units'] = 'm'\n",
    "    era5_ds['t'].attrs['units'] = 'K'\n",
    "    era5_ds['rh'].attrs['units'] = '%'\n",
    "    era5_ds['p'].attrs['units'] = 'Pa'\n",
    "    era5_ds['iwv'].attrs['units'] = 'kg/m^2'\n",
    "    era5_ds['cwp'].attrs['units'] = 'kg/m^2'\n",
    "    era5_ds['iwp'].attrs['units'] = 'kg/m^2'\n",
    "    era5_ds['rwp'].attrs['units'] = 'kg/m^2'\n",
    "    era5_ds['swp'].attrs['units'] = 'kg/m^2'\n",
    "\n",
    "    era5_ds.to_netcdf(outPath + 'era5_'+era5_datetime+\"_atmos.nc\")\n",
    "    \n",
    "    return pam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAMTRA Output Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDataHyd(lon,lat,data):\n",
    "    data[data < 0.05] = np.nan\n",
    "    \n",
    "    map_proj=ccrs.Mollweide(central_longitude=-30)\n",
    "    data_proj=ccrs.PlateCarree()\n",
    "    ax = plt.subplot(221,projection=map_proj)\n",
    "    ax.coastlines()\n",
    "    plt.pcolormesh(lon,lat,data[:,:,0],transform=data_proj,cmap='jet')\n",
    "    plt.colorbar()\n",
    "    ax = plt.subplot(222,projection=map_proj)\n",
    "    ax.coastlines()\n",
    "    plt.pcolormesh(lon,lat,data[:,:,1],transform=data_proj,cmap='jet')\n",
    "    plt.colorbar()\n",
    "    ax = plt.subplot(223,projection=map_proj)\n",
    "    ax.coastlines()\n",
    "    plt.pcolormesh(lon,lat,data[:,:,2],transform=data_proj,cmap='jet')\n",
    "    plt.colorbar()\n",
    "    ax = plt.subplot(224,projection=map_proj)\n",
    "    ax.coastlines()\n",
    "    plt.pcolormesh(lon,lat,data[:,:,3],transform=data_proj,cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def plotMap(lon,lat,data):\n",
    "    proj = ccrs.NorthPolarStereo(central_longitude=10)\n",
    "    data_crs = ccrs.PlateCarree()\n",
    "    ax = plt.axes(projection=proj)\n",
    "    ax.coastlines()\n",
    "    plt.pcolormesh(lon,lat,data[:,:],transform=data_crs,cmap='jet')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Main Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Cdo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d5793c25d829>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                         outPath='/scratch/b/b380702/',area=[-30,50,65,89])\n\u001b[0;32m      4\u001b[0m \u001b[1;31m## ---> which output path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mera5_processing_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunCDO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mera5_processing_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadERA5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minPath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'/scratch/b/b380702/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcut_levels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-216dad0f93fe>\u001b[0m in \u001b[0;36mrunCDO\u001b[1;34m(self, timestep)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrunCDO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mcdo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCdo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0myyyy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myyyy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mmm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%02d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Cdo' is not defined"
     ]
    }
   ],
   "source": [
    "era5_processing_cls=ERA5_Preprocessing(2016,10,13,\n",
    "                        '/home/b/b380702/pamtra/descriptorfiles/descriptor_file_ecmwf.txt',\n",
    "                        outPath='/scratch/b/b380702/',area=[-30,50,65,89])\n",
    "## ---> which output path      \n",
    "era5_processing_cls.runCDO()\n",
    "\n",
    "era5_processing_cls.readERA5(inPath='/scratch/b/b380702/',step=4,cut_levels=5)\n",
    "pam=era5_processing_cls.pam\n",
    "#pam._shape2D\n",
    "\n",
    "# reduce to just ocean grid points\n",
    "filter = np.empty(pam._shape2D,dtype=bool)\n",
    "filter[:,:] = False\n",
    "filter[pam.p['sfc_type'] == 0] = True\n",
    "pam.filterProfiles(filter)\n",
    "#pam._shape2D\n",
    "runPAMTRA(era5_processing_cls,era5_datetime)\n",
    "#pam.r['tb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMap(pam.p['lon'],pam.p['lat'],pam.r['tb'][:,:,0,6,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
