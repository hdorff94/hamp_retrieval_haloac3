{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyPamtra\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# import regression packages\n",
    "current_path=os.getcwd()\n",
    "sys.path.insert(1,current_path+\"/../src/\")\n",
    "sys.path.insert(2,current_path+\"/../retrieval\")\n",
    "import ERA5_Tb ##---> needed to work with PAMTRA simulated TBs\n",
    "import Regression_Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates the input for readERA5\n",
    "from cdo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulation=True\n",
    "take_random_spring=True\n",
    "take_synth_ar_dates=True\n",
    "#second_time=True\n",
    "rerun_dates=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ERA5 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_preprocess=ERA5_Tb.ERA5_Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PAMTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAMTRAhandler=ERA5_Tb.PAMTRA_Handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAMTRA Output Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDataHyd(lon,lat,data):\n",
    "    data[data < 0.05] = np.nan\n",
    "    \n",
    "    map_proj=ccrs.Mollweide(central_longitude=-30)\n",
    "    data_proj=ccrs.PlateCarree()\n",
    "    ax = plt.subplot(221,projection=map_proj)\n",
    "    ax.coastlines()\n",
    "    plt.pcolormesh(lon,lat,data[:,:,0],transform=data_proj,cmap='jet')\n",
    "    plt.colorbar()\n",
    "    ax = plt.subplot(222,projection=map_proj)\n",
    "    ax.coastlines()\n",
    "    plt.pcolormesh(lon,lat,data[:,:,1],transform=data_proj,cmap='jet')\n",
    "    plt.colorbar()\n",
    "    ax = plt.subplot(223,projection=map_proj)\n",
    "    ax.coastlines()\n",
    "    plt.pcolormesh(lon,lat,data[:,:,2],transform=data_proj,cmap='jet')\n",
    "    plt.colorbar()\n",
    "    ax = plt.subplot(224,projection=map_proj)\n",
    "    ax.coastlines()\n",
    "    plt.pcolormesh(lon,lat,data[:,:,3],transform=data_proj,cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def plotMap(lon,lat,data):\n",
    "    proj = ccrs.NorthPolarStereo(central_longitude=10)\n",
    "    data_crs = ccrs.PlateCarree()\n",
    "    ax = plt.axes(projection=proj)\n",
    "    ax.coastlines()\n",
    "    plt.pcolormesh(lon,lat,data[:,:],transform=data_crs,cmap='jet')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Main Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20160311', '20180224', '20180225']\n"
     ]
    }
   ],
   "source": [
    "def create_random_dates(old_dates,number_of_dates=3):\n",
    "    #dates=['19820320','19900409', '19910428', '19950306', '19970322','20050418','20170425','20210331']\n",
    "    #dates=['20040301', '19970410', '20060417', '19940330', '20140322', '19950410', '19990423', '20190421'] #second dates\n",
    "    import random\n",
    "    dates=[]\n",
    "    d=0\n",
    "    while d <number_of_dates:\n",
    "        year=random.randint(1979,2021)\n",
    "        month=random.randint(3,4)\n",
    "        if month==3:\n",
    "            day=random.randint(1,31)\n",
    "        else:\n",
    "            day=random.randint(1,30)    \n",
    "        \n",
    "        date=str(year*10000+month*100+day)\n",
    "        if not date in old_dates:\n",
    "            dates.append(date)\n",
    "            d+=1\n",
    "    return dates\n",
    "\n",
    "hour_to_analyse=\"12\" # UTC\n",
    "\n",
    "dates=[\"20220315\"]#[\"20150314\",\"20160311\",\"20161013\",\"20180224\",\"20180225\",\"20190319\",\"20200416\",\"20200419\"]\n",
    "old_dates=[\"19820320\",'19900409', #'19910428',\n",
    "           #'19950306', '19970322',\n",
    "           #'20050418',\n",
    "           '20170425','20210331', \"20040301\",#random dates\n",
    "           #, '19970410', '20060417', '19940330', '20140322', '19950410', '19990423', '20190421', #second random dates\n",
    "           \"20110317\",\n",
    "           \"20110423\",\n",
    "           \"20150314\",\n",
    "            \"20160311\",\"20180224\",\n",
    "           #\"20161013\",\n",
    "           \"20180225\",\"20190319\",\n",
    "           \"20200416\",\"20200419\", # synth AR dates\n",
    "          ]\n",
    "new_dates=[#'20190411', \n",
    "    #'20020413', \n",
    "    #'19920330', \n",
    "    #'19900312',\n",
    "    #'20200420',\n",
    "    #'19950404', '20210421', \n",
    "    #'20170301', '19790313','19860407', '20160411', \n",
    "    #'20140320', '19930304', '19790426',\n",
    "    #'20020401', '19920415', '19820322',\n",
    "    #'19840425', '19820414', '20060330'\n",
    "    ]\n",
    "if take_random_spring:\n",
    "    if rerun_dates:\n",
    "        dates=create_random_dates(old_dates,number_of_dates=15)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    # default 50 dates\n",
    "    dates=['19790312', '19810330', '19810424', '19820320', '19820416',\n",
    "           '19830316', '19830331', '19830414', '19840308', '19840413',\n",
    "           '19840428', '19880330', '19890422', '19900409', '19900411', '19900418', \n",
    "           '19910301', '19910428', '19920302','19920413', '19930303', '19930430',\n",
    "           '19940421', '19950306', '19950317', '19970322', '19980324', '19980409', \n",
    "           '20030415', '20050401', '20060317', '20070324',\n",
    "           '20080313', '20080404', '20080411', '20080430', '20090324', '20100323', '20110311', '20110329', \n",
    "           '20110413', '20120312','20130313','20140309', '20140330', '20160409', '20180319', '20180326', \n",
    "        '20200326','20210402',#'#20220315', \n",
    "        '20220310'\n",
    "           #'20220316', '20220410'\n",
    "    ]\n",
    "if take_synth_ar_dates:\n",
    "    dates=[#\"20110317\",\"20110423\",#\"20150314\",\n",
    "           \"20160311\",\"20180224\",\"20180225\",\n",
    "           #\"20190319\",\"20200416\",\"20200419\"\n",
    "          ]\n",
    "    \n",
    "#dates=['19820320', '19840308',#\n",
    "\n",
    "#       '19900409', '19910428',\n",
    "#       '19950306', '19970322', \n",
    "#       '20080313', '20110311',\n",
    "#       '20110413'\n",
    "#      ]\n",
    "#dates=[\"20220315\",\"20220316\",\"20220410\"]\n",
    "#old_dates#[\"20220312\",\"20220313\",\n",
    "      #  \"20220314\",\n",
    "      # \"20220315\",\"20220316\"\n",
    "      #]#\"20220312\",\"20220313\",\"20220314\",\"20220315\",\"20220316\",\"20220320\",\"20220321\"]#new_dates\n",
    "#dates=['19820416', '19880330', '20080411']\n",
    "#dates=['19810424', '19840428', '19890422', '19900418', '19910301', '19930303', '19980324', '19980409', '20030415', '20060317', '20080404', '20080430', '20100323', '20140330', '20180319']\n",
    "print(sorted(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20160311\n",
      "Current Time = 11:20:00\n",
      "Version of 2023-05-16 runned\n",
      "File to check: /scratch/u/u300737/reduced_ml_20160311_12_130.nc\n",
      "All sf files now calculated\n",
      "all IV files calculated\n",
      "CDO done\n",
      "entire ERA5 read\n",
      "PAMTRA TBs not there already, they should be calculated\n",
      "passive\n",
      "OUTPUT path: /scratch/u/u300737/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u/u300737/lib/python/pyPamtra/core.py:838: Warning: sfc_salinity set to 33.0\n",
      "  warnings.warn(\"%s set to %s\"%(environment,preset,), Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:871: Warning: obs_height set to [833000.0, 0.0]\n",
      "  warnings.warn(\"%s set to %s\"%(environment,preset,), Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:881: Warning: hydro_reff set to 0\n",
      "  warnings.warn(qValue + \" set to 0\", Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:881: Warning: hydro_n set to 0\n",
      "  warnings.warn(qValue + \" set to 0\", Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:892: Warning: airturb set to nan\n",
      "  warnings.warn(qValue + \" set to nan\", Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:892: Warning: wind_w set to nan\n",
      "  warnings.warn(qValue + \" set to nan\", Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:892: Warning: wind_uv set to nan\n",
      "  warnings.warn(qValue + \" set to nan\", Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:892: Warning: turb_edr set to nan\n",
      "  warnings.warn(qValue + \" set to nan\", Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAMTRA Simulation stored as: /scratch/u/u300737/20160311_12_passive.nc\n",
      "ERA Files saved as: /scratch/u/u300737/era5_20160311_12_atmos.nc\n",
      "PAMTRA saved as: /scratch/u/u300737/pamtra_hamp_20160311_12.nc\n",
      "20180224\n",
      "Current Time = 11:49:12\n",
      "Version of 2023-05-16 runned\n",
      "File to check: /scratch/u/u300737/reduced_ml_20180224_12_130.nc\n",
      "All sf files now calculated\n",
      "all IV files calculated\n",
      "CDO done\n",
      "entire ERA5 read\n",
      "PAMTRA TBs not there already, they should be calculated\n",
      "passive\n",
      "OUTPUT path: /scratch/u/u300737/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u/u300737/lib/python/pyPamtra/core.py:838: Warning: sfc_salinity set to 33.0\n",
      "  warnings.warn(\"%s set to %s\"%(environment,preset,), Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:871: Warning: obs_height set to [833000.0, 0.0]\n",
      "  warnings.warn(\"%s set to %s\"%(environment,preset,), Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:881: Warning: hydro_reff set to 0\n",
      "  warnings.warn(qValue + \" set to 0\", Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:881: Warning: hydro_n set to 0\n",
      "  warnings.warn(qValue + \" set to 0\", Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:892: Warning: airturb set to nan\n",
      "  warnings.warn(qValue + \" set to nan\", Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:892: Warning: wind_w set to nan\n",
      "  warnings.warn(qValue + \" set to nan\", Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:892: Warning: wind_uv set to nan\n",
      "  warnings.warn(qValue + \" set to nan\", Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:892: Warning: turb_edr set to nan\n",
      "  warnings.warn(qValue + \" set to nan\", Warning)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "if run_simulation:\n",
    "    import ERA5_Tb\n",
    "    default_area=[-30,50,65,89]#[5,10,65,70]\n",
    "    for date in sorted(dates):\n",
    "        print(date)\n",
    "        yyyy = int(date[0:4])\n",
    "        mm   = int(date[4:6])\n",
    "        dd   = int(date[6:8])\n",
    "        now = datetime.now()\n",
    "\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(\"Current Time =\", current_time)\n",
    "\n",
    "        era5_processing_cls=ERA5_preprocess(yyyy,mm,dd,\n",
    "                        '/home/b/b380702/pamtra/descriptorfiles/descriptor_file_ecmwf.txt',\n",
    "                        outPath='/scratch/u/u300737/',area=default_area,timestep=int(hour_to_analyse)+1)\n",
    "        temporary_pamtrahandler=PAMTRAhandler(era5_processing_cls)\n",
    "        ## ---> which output path      \n",
    "        era5_processing_cls.runCDO()\n",
    "        print(\"CDO done\")\n",
    "        era5_existent,pamtra_existent=era5_processing_cls.checkfor_era5_pamtra_files()\n",
    "        if not era5_existent:\n",
    "            era5_processing_cls.readERA5(inPath='/scratch/u/u300737/',step=4,cut_levels=5)\n",
    "            era5_processing_cls.create_pamData_dict(step=4)\n",
    "            print(\"entire ERA5 read\")\n",
    "        else:\n",
    "            print(\"Processed ERA5 already created\")\n",
    "            \n",
    "        pamtrahandler=PAMTRAhandler(era5_processing_cls)\n",
    "        if not pamtra_existent:\n",
    "            print(\"PAMTRA TBs not there already, they should be calculated\")\n",
    "            if run_simulation:\n",
    "                # reduce to just ocean grid points\n",
    "                filter = np.empty(era5_processing_cls.pam._shape2D,dtype=bool)\n",
    "                filter[:,:] = False\n",
    "                filter[era5_processing_cls.pam.p['sfc_type'] == 0] = True\n",
    "                era5_processing_cls.pam.filterProfiles(filter)\n",
    "                pamtrahandler.runPAMTRA()\n",
    "                pamtrahandler.collectERA5()\n",
    "                pamtrahandler.reducePAMTRAResults(instrument='hamp')\n",
    "        else:\n",
    "            print(\"PAMTRA TBs already calculated\")\n",
    "#pam.r['tb'].shape\n",
    "#pamtrahandler.pam.r['tb'].shape\n",
    "#plotMap(pamtrahandler.pam.p['lon'],pamtrahandler.pam.p['lat'],pamtrahandler.pam.r['tb'][:,:,0,6,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move all pamtra hamp files to another directory #work\n",
    "import subprocess\n",
    "import glob\n",
    "old_pamtra_outp_path=\"/scratch/u/u300737/\"#pamtra_hamp_20200326_12.nc\n",
    "old_file_list=glob.glob(old_pamtra_outp_path+\"pamtra_hamp_*\")\n",
    "new_pamtra_outp_path=\"/work/bb1320/hdorff/pamtra_hamp_retrieval/\"\n",
    "if not os.path.exists(new_pamtra_outp_path):\n",
    "    os.makedirs(new_pamtra_outp_path)\n",
    "for file in old_file_list:\n",
    "    file_name=file.split(\"/\")[-1]\n",
    "    #print(file_name)\n",
    "    status = subprocess.call('cp '+file+\" \"+new_pamtra_outp_path+file_name, shell=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move all ERA5 hamp files to another directory #work\n",
    "old_era5_outp_path=\"/scratch/u/u300737/\"#pamtra_hamp_20200326_12.nc\n",
    "old_file_list=glob.glob(old_pamtra_outp_path+\"era5_*\")\n",
    "new_era5_outp_path=\"/work/bb1320/hdorff/pamtra_hamp_retrieval/\"\n",
    "if not os.path.exists(new_era5_outp_path):\n",
    "    os.makedirs(new_era5_outp_path)\n",
    "for file in old_file_list:\n",
    "    file_name=file.split(\"/\")[-1]\n",
    "    #print(file_name)\n",
    "    status = subprocess.call('cp '+file+\" \"+new_era5_outp_path+file_name, shell=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#era_ds=xr.open_dataset(\"/scratch/u/u300737/era5_\"+date+\"_\"+hour_to_analyse+\"_atmos.nc\")\n",
    "#era_ds.obs_height_values\n",
    "pamtra_ds=xr.open_dataset(new_pamtra_outp_path+file_name)\n",
    "pamtra_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_ds=xr.open_dataset(\"/scratch/u/u300737/era5_\"+date+\"_\"+hour_to_analyse+\"_atmos.nc\")\n",
    "era_ds=xr.open_dataset(new_era5_outp_path+file_name)\n",
    "era_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (based on the module python3/2023.01)",
   "language": "python",
   "name": "python3_2023_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
