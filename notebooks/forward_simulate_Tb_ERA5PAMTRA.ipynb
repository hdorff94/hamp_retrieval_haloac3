{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook preprocesses the ERA5 data for PAMTRA. \n",
    "As a second step, this notebook forward-simulates the brightness temperatures for the HAMP radiometer channels (Mech et al., 2014, https://doi.org/10.5194/amt-7-4539-2014),\n",
    "using the ERA5 training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyPamtra\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# import regression packages\n",
    "current_path=os.getcwd()\n",
    "sys.path.insert(1,current_path+\"/../src/\")\n",
    "sys.path.insert(2,current_path+\"/../retrieval\")\n",
    "import ERA5_Tb               ##---> needed to work with PAMTRA simulated TBs\n",
    "import Regression_Retrieval  ##---> class for executing the regression retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates the input of ERA5 for handling in the readERA5 module\n",
    "from cdo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/work/bb1086/pamtra_hamp_retrieval/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining if new simulations shall be conducted and which training data should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulation=True\n",
    "take_random_spring=False\n",
    "take_synth_ar_dates=True\n",
    "rerun_dates=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ERA5 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising the ERA5 preprocessing class for later use in PAMTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_preprocess=ERA5_Tb.ERA5_Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PAMTRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising the PAMTRA_Handler class that is the linkage between preprocessed ERA5 and PAMTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAMTRAhandler=ERA5_Tb.PAMTRA_Handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAMTRA Output Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some quicklook PAMTRA illustrations, not further used in the routine, but useful for quick data analysis.\n",
    "def plotDataHyd(lon,lat,data):\n",
    "    data[data < 0.05] = np.nan\n",
    "    \n",
    "    map_proj=ccrs.Mollweide(central_longitude=-30)\n",
    "    data_proj=ccrs.PlateCarree()\n",
    "    ax = plt.subplot(221,projection=map_proj)\n",
    "    ax.coastlines()\n",
    "    plt.pcolormesh(lon,lat,data[:,:,0],transform=data_proj,cmap='jet')\n",
    "    plt.colorbar()\n",
    "    ax = plt.subplot(222,projection=map_proj)\n",
    "    ax.coastlines()\n",
    "    plt.pcolormesh(lon,lat,data[:,:,1],transform=data_proj,cmap='jet')\n",
    "    plt.colorbar()\n",
    "    ax = plt.subplot(223,projection=map_proj)\n",
    "    ax.coastlines()\n",
    "    plt.pcolormesh(lon,lat,data[:,:,2],transform=data_proj,cmap='jet')\n",
    "    plt.colorbar()\n",
    "    ax = plt.subplot(224,projection=map_proj)\n",
    "    ax.coastlines()\n",
    "    plt.pcolormesh(lon,lat,data[:,:,3],transform=data_proj,cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def plotMap(lon,lat,data):\n",
    "    proj = ccrs.NorthPolarStereo(central_longitude=10)\n",
    "    data_crs = ccrs.PlateCarree()\n",
    "    ax = plt.axes(projection=proj)\n",
    "    ax.coastlines()\n",
    "    plt.pcolormesh(lon,lat,data[:,:],transform=data_crs,cmap='jet')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data day generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_dates(old_dates,number_of_dates=3):\n",
    "    \"\"\"\n",
    "    This routine defines random dates from spring season (March, April) out of the year range from 1979 to 2021.\n",
    "\n",
    "    Input:\n",
    "\n",
    "    old_dates: list\n",
    "        Dates (as strings) that are already defined. They will be checked for not being repeated\n",
    "\n",
    "    number_of_dates: int\n",
    "        Number of dates that should be chosen randomnly. Default is 3. Mostly 50 are used.\n",
    "\n",
    "    Returns:\n",
    "    \n",
    "    dates: list\n",
    "        Dates to consider as a list of strings.\n",
    "    \"\"\"\n",
    "    import random\n",
    "    dates=[]\n",
    "    d=0\n",
    "    while d <number_of_dates:\n",
    "        year=random.randint(1979,2021)\n",
    "        month=random.randint(3,4)\n",
    "        if month==3:\n",
    "            day=random.randint(1,31)\n",
    "        else:\n",
    "            day=random.randint(1,30)    \n",
    "        \n",
    "        date=str(year*10000+month*100+day)\n",
    "        if not date in old_dates:\n",
    "            dates.append(date)\n",
    "            d+=1\n",
    "    return dates\n",
    "\n",
    "def get_dates(specific_dates=[],rerun_dates=True,take_random_dates=True,take_synth_ar_dates=False,\n",
    "             no_of_dates=5):\n",
    "    \"\"\"\n",
    "    This routine gets all the dates. \n",
    "    \n",
    "    Input:\n",
    "        specific_dates: list\n",
    "            List of specific dates to be used in any way. Default is empty list.\n",
    "        rerun_dates: boolean\n",
    "            if yes, new dates are used, else old ones are used using PAMTRASIM_analysis\n",
    "    \"\"\"\n",
    "    if len(specific_dates)!=0:\n",
    "        if take_random_dates:\n",
    "            if rerun_dates:\n",
    "                #Add randomn dates to specific dates\n",
    "                create_random_dates(specific_dates,number_of_dates=no_of_dates)\n",
    "            else:\n",
    "                import PAMTRA_sim_analysis\n",
    "                PAMTRASIM_analysis=PAMTRA_sim_analysis.PAMTRASIM_analysis\n",
    "                all_available_days=PAMTRASIM_analysis.list_all_simulated_days(\n",
    "                    data_path=\"/work/bb1086/pamtra_hamp_retrieval/\",hour=hour_to_analyse)\n",
    "        if take_synth_ar_dates:\n",
    "            dates=[\"20110317\",\"20110423\",\"20150314\",\"20160311\",\"20180224\",\"20180225\",\n",
    "                       \"20190319\",\"20200416\",\"20200419\"]\n",
    "        else:\n",
    "            # Use just the specific dates\n",
    "            dates=specific_dates\n",
    "    else:\n",
    "        # Default training dataset.\n",
    "        dates=['19790312', '19810330', '19810424', '19820320', '19820416','19830316', \n",
    "               '19830331', '19830414', '19840308', '19840413','19840428', '19880330', \n",
    "               '19890422', '19900409', '19900411', '19900418', '19910301', '19910428', \n",
    "               '19920302','19920413', '19930303', '19930430','19940421', '19950306', \n",
    "               '19950317', '19970322', '19980324', '19980409', '20030415', '20050401',\n",
    "               '20060317', '20070324','20080313', '20080404', '20080411', '20080430', \n",
    "               '20090324', '20100323', '20110311', '20110329', '20110413', '20120312',\n",
    "               '20130313','20140309', '20140330', '20160409', '20180319', '20180326', \n",
    "               '20200326','20210402', '20220310']\n",
    "    return dates        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Main Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: ['20110317', '20110423', '20150314', '20160311', '20180224', '20180225', '20190319', '20200416', '20200419']\n"
     ]
    }
   ],
   "source": [
    "hour_to_analyse=\"10\" # UTC\n",
    "specific_dates=[\"20150314\"]\n",
    "dates=get_dates(specific_dates=specific_dates,take_random_dates=False,take_synth_ar_dates=take_synth_ar_dates)\n",
    "print(\"Training data:\", sorted(dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over all days and preprocess the ERA5 data that is then implemented into PAMTRA by the PAMTRA handler. \n",
    "If the corresponding files are already there, they are simply loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20110317\n",
      "Current Time = 15:19:36\n",
      "Version of 2023-05-16 runned\n",
      "File to check: /scratch/u/u300737/reduced_ml_20110317_10_130.nc\n",
      "All sf files now calculated\n",
      "all IV files calculated\n",
      "CDO done\n",
      "entire ERA5 read\n",
      "PAMTRA TBs not there already, they should be calculated\n",
      "passive\n",
      "OUTPUT path: /scratch/u/u300737/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u/u300737/lib/python/pyPamtra/core.py:838: Warning: sfc_salinity set to 33.0\n",
      "  warnings.warn(\"%s set to %s\"%(environment,preset,), Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:871: Warning: obs_height set to [833000.0, 0.0]\n",
      "  warnings.warn(\"%s set to %s\"%(environment,preset,), Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:881: Warning: hydro_reff set to 0\n",
      "  warnings.warn(qValue + \" set to 0\", Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:881: Warning: hydro_n set to 0\n",
      "  warnings.warn(qValue + \" set to 0\", Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:892: Warning: airturb set to nan\n",
      "  warnings.warn(qValue + \" set to nan\", Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:892: Warning: wind_w set to nan\n",
      "  warnings.warn(qValue + \" set to nan\", Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:892: Warning: wind_uv set to nan\n",
      "  warnings.warn(qValue + \" set to nan\", Warning)\n",
      "/home/u/u300737/lib/python/pyPamtra/core.py:892: Warning: turb_edr set to nan\n",
      "  warnings.warn(qValue + \" set to nan\", Warning)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "if run_simulation:\n",
    "    import ERA5_Tb\n",
    "    default_area=[-30,50,65,89]#[5,10,65,70]\n",
    "    for date in sorted(dates):\n",
    "        print(date)\n",
    "        yyyy = int(date[0:4])\n",
    "        mm   = int(date[4:6])\n",
    "        dd   = int(date[6:8])\n",
    "        now = datetime.now()\n",
    "\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(\"Current Time =\", current_time)\n",
    "\n",
    "        era5_processing_cls=ERA5_preprocess(yyyy,mm,dd,\n",
    "                        '/home/b/b380702/pamtra/descriptorfiles/descriptor_file_ecmwf.txt',\n",
    "                        outPath='/scratch/u/u300737/',area=default_area,timestep=int(hour_to_analyse)+1)\n",
    "        temporary_pamtrahandler=PAMTRAhandler(era5_processing_cls)\n",
    "        ## ---> which output path      \n",
    "        era5_processing_cls.runCDO()\n",
    "        print(\"CDO done\")\n",
    "        era5_existent,pamtra_existent=era5_processing_cls.checkfor_era5_pamtra_files()\n",
    "        if not era5_existent:\n",
    "            era5_processing_cls.readERA5(inPath='/scratch/u/u300737/',step=4,cut_levels=5)\n",
    "            era5_processing_cls.create_pamData_dict(step=4)\n",
    "            print(\"entire ERA5 read\")\n",
    "        else:\n",
    "            print(\"Processed ERA5 already created\")\n",
    "            \n",
    "        pamtrahandler=PAMTRAhandler(era5_processing_cls)\n",
    "        if not pamtra_existent:\n",
    "            print(\"PAMTRA TBs not there already, they should be calculated\")\n",
    "            if run_simulation:\n",
    "                # reduce to just ocean grid points\n",
    "                filter = np.empty(era5_processing_cls.pam._shape2D,dtype=bool)\n",
    "                filter[:,:] = False\n",
    "                filter[era5_processing_cls.pam.p['sfc_type'] == 0] = True\n",
    "                era5_processing_cls.pam.filterProfiles(filter)\n",
    "                pamtrahandler.runPAMTRA()\n",
    "                pamtrahandler.collectERA5()\n",
    "                pamtrahandler.reducePAMTRAResults(instrument='hamp')\n",
    "        else:\n",
    "            print(\"PAMTRA TBs already calculated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### move all pamtra hamp files to another directory for long-term storage #work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import glob\n",
    "old_pamtra_outp_path=\"/scratch/u/u300737/\"\n",
    "old_file_list=glob.glob(old_pamtra_outp_path+\"pamtra_hamp_*\")\n",
    "new_pamtra_outp_path=data_path\n",
    "if not os.path.exists(new_pamtra_outp_path):\n",
    "    os.makedirs(new_pamtra_outp_path)\n",
    "for file in old_file_list:\n",
    "    file_name=file.split(\"/\")[-1]\n",
    "    status = subprocess.call('cp '+file+\" \"+new_pamtra_outp_path+file_name, shell=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show last PAMTRA file\n",
    "pamtra_ds=xr.open_dataset(new_pamtra_outp_path+file_name)\n",
    "pamtra_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move all ERA5 hamp files to another directory #work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_era5_outp_path=\"/scratch/u/u300737/\"#pamtra_hamp_20200326_12.nc\n",
    "old_file_list=glob.glob(old_pamtra_outp_path+\"era5_*\")\n",
    "new_era5_outp_path=data_path\n",
    "if not os.path.exists(new_era5_outp_path):\n",
    "    os.makedirs(new_era5_outp_path)\n",
    "for file in old_file_list:\n",
    "    file_name=file.split(\"/\")[-1]\n",
    "    #print(file_name)\n",
    "    status = subprocess.call('cp '+file+\" \"+new_era5_outp_path+file_name, shell=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show last ERA5 file\n",
    "era5_ds=xr.open_dataset(new_pamtra_outp_path+\"era5_\"+date+\"_\"+hour_to_analyse+\"_atmos.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1 Python 3 (based on the module python3/2023.01)",
   "language": "python",
   "name": "python3_2023_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
